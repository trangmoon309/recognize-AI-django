arguments: src/align_dataset_mtcnn.py Dataset/FaceData/raw Dataset/FaceData/processed --image_size 160 --margin 32 --random_order --gpu_memory_fraction 0.25
--------------------
tensorflow version: 2.5.0-rc0
--------------------
git hash: b'62b1e0c7a4ede2deb8388de8933d08a7f487b159'
--------------------
b'diff --git a/requirements.txt b/requirements.txt\nindex f7084e9..ee2c5bf 100644\n--- a/requirements.txt\n+++ b/requirements.txt\n@@ -1,6 +1,6 @@\n-tensorflow==1.15.5\n-keras==2.3.1\n-scipy==1.1.0\n+tensorflow\n+keras\n+scipy\n scikit-learn\n opencv-python\n h5py\ndiff --git a/src/align/detect_face.py b/src/align/detect_face.py\nindex 7f98ca7..49f0b39 100644\n--- a/src/align/detect_face.py\n+++ b/src/align/detect_face.py\n@@ -29,10 +29,12 @@ from __future__ import print_function\n from six import string_types, iteritems\n \n import numpy as np\n-import tensorflow as tf\n+import tensorflow.compat.v1 as tf\n #from math import floor\n import cv2\n import os\n+import imageio\n+\n \n def layer(op):\n     """Decorator for composable network layers."""\n@@ -82,7 +84,7 @@ class Network(object):\n         session: The current TensorFlow session\n         ignore_missing: If true, serialized weights for missing layers are ignored.\n         """\n-        data_dict = np.load(data_path, encoding=\'latin1\').item() #pylint: disable=no-member\n+        data_dict = np.load(data_path, encoding=\'latin1\',allow_pickle=True).item() #pylint: disable=no-member\n \n         for op_name in data_dict:\n             with tf.variable_scope(op_name, reuse=True):\n@@ -191,7 +193,7 @@ class Network(object):\n                     dim *= int(d)\n                 feed_in = tf.reshape(inp, [-1, dim])\n             else:\n-                feed_in, dim = (inp, input_shape[-1].value)\n+                feed_in, dim = (inp, input_shape[-1])\n             weights = self.make_var(\'weights\', shape=[dim, num_out])\n             biases = self.make_var(\'biases\', [num_out])\n             op = tf.nn.relu_layer if relu else tf.nn.xw_plus_b\ndiff --git a/src/align_dataset_mtcnn.py b/src/align_dataset_mtcnn.py\nindex 7d5e735..e135b73 100644\n--- a/src/align_dataset_mtcnn.py\n+++ b/src/align_dataset_mtcnn.py\n@@ -29,12 +29,15 @@ from scipy import misc\n import sys\n import os\n import argparse\n-import tensorflow as tf\n+import tensorflow.compat.v1 as tf\n import numpy as np\n import facenet\n import align.detect_face\n import random\n from time import sleep\n+import imageio\n+from skimage.transform import resize\n+#126 \n \n def main(args):\n     sleep(random.random())\n@@ -80,7 +83,7 @@ def main(args):\n                 print(image_path)\n                 if not os.path.exists(output_filename):\n                     try:\n-                        img = misc.imread(image_path)\n+                        img = imageio.imread(image_path)\n                     except (IOError, ValueError, IndexError) as e:\n                         errorMessage = \'{}: {}\'.format(image_path, e)\n                         print(errorMessage)\n@@ -121,14 +124,16 @@ def main(args):\n                                 bb[2] = np.minimum(det[2]+args.margin/2, img_size[1])\n                                 bb[3] = np.minimum(det[3]+args.margin/2, img_size[0])\n                                 cropped = img[bb[1]:bb[3],bb[0]:bb[2],:]\n-                                scaled = misc.imresize(cropped, (args.image_size, args.image_size), interp=\'bilinear\')\n+                                #scaled = misc.imresize(cropped, (args.image_size, args.image_size), interp=\'bilinear\')\n+                                scaled = resize(cropped, output_shape=(args.image_size,args.image_size))\n+\n                                 nrof_successfully_aligned += 1\n                                 filename_base, file_extension = os.path.splitext(output_filename)\n                                 if args.detect_multiple_faces:\n                                     output_filename_n = "{}_{}{}".format(filename_base, i, file_extension)\n                                 else:\n                                     output_filename_n = "{}{}".format(filename_base, file_extension)\n-                                misc.imsave(output_filename_n, scaled)\n+                                imageio.imwrite(output_filename_n, scaled)\n                                 text_file.write(\'%s %d %d %d %d\\n\' % (output_filename_n, bb[0], bb[1], bb[2], bb[3]))\n                         else:\n                             print(\'Unable to align "%s"\' % image_path)\ndiff --git a/src/classifier.py b/src/classifier.py\nindex e7189bc..0c5c288 100644\n--- a/src/classifier.py\n+++ b/src/classifier.py\n@@ -26,7 +26,7 @@ from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v1 as tf\n import numpy as np\n import argparse\n import facenet\n@@ -85,6 +85,7 @@ def main(args):\n                 paths_batch = paths[start_index:end_index]\n                 images = facenet.load_data(paths_batch, False, False, args.image_size)\n                 feed_dict = { images_placeholder:images, phase_train_placeholder:False }\n+                # tr\xe1\xba\xa3 v\xe1\xbb\x81 danh s\xc3\xa1ch embedded vectors\n                 emb_array[start_index:end_index,:] = sess.run(embeddings, feed_dict=feed_dict)\n             \n             classifier_filename_exp = os.path.expanduser(args.classifier_filename)\n@@ -92,8 +93,17 @@ def main(args):\n             if (args.mode==\'TRAIN\'):\n                 # Train classifier\n                 print(\'Training classifier\')\n+                \n+                # D\xc3\xb9ng SVC \xc4\x91\xe1\xbb\x83 t\xc3\xacm ki\xe1\xba\xbfm, ph\xc3\xa2n l\xe1\xbb\x9bp\n+                # input: danh s\xc3\xa1ch c\xc3\xa1c embedded vector v\xc3\xa0 danh s\xc3\xa1ch labels\n+                # output: ph\xc3\xa2n c\xc3\xa1c vector ra theo l\xe1\xbb\x9bp\n                 model = SVC(kernel=\'linear\', probability=True)\n                 model.fit(emb_array, labels)\n+\n+                # \xc4\x90\xe1\xbb\x83 d\xc3\xb9ng FAISS:\n+                # B\xc6\xb0\xe1\xbb\x9bc 1: T\xe1\xba\xa1o index cho c\xc3\xa1c vector(ph\xc3\xa2n c\xc3\xa1c vector ra theo index), l\xc6\xb0u xu\xe1\xbb\x91ng file bin\n+                # B\xc6\xb0\xe1\xbb\x9bc 2: D\xe1\xbb\xb1a v\xc3\xa0o t\xe1\xba\xadp index \xc4\x91\xc3\xa3 t\xe1\xba\xa1o, t\xc3\xacm ki\xe1\xba\xbfm c\xc3\xa1c \xe1\xba\xa3nh c\xc3\xb3 distance nh\xe1\xbb\x8f nh\xe1\xba\xa5t\n+                #Create Index\n             \n                 # Create a list of class names\n                 class_names = [ cls.name.replace(\'_\', \' \') for cls in dataset]\ndiff --git a/src/face_rec_cam.py b/src/face_rec_cam.py\nindex cfbd4f4..eacc640 100644\n--- a/src/face_rec_cam.py\n+++ b/src/face_rec_cam.py\n@@ -2,10 +2,8 @@ from __future__ import absolute_import\n from __future__ import division\n from __future__ import print_function\n \n-import tensorflow as tf\n+import tensorflow.compat.v1 as tf\n from imutils.video import VideoStream\n-\n-\n import argparse\n import facenet\n import imutils\n@@ -18,6 +16,7 @@ import numpy as np\n import cv2\n import collections\n from sklearn.svm import SVC\n+from sklearn.metrics.pairwise import cosine_similarity\n \n \n def main():\n@@ -63,6 +62,24 @@ def main():\n \n             cap  = VideoStream(src=0).start()\n \n+            # Chu\xe1\xba\xa9n b\xe1\xbb\x8b d\xe1\xbb\xaf li\xe1\xbb\x87u v\xe1\xbb\x81 c\xc3\xa1c vectors v\xe1\xbb\x81 h\xc3\xacnh \xe1\xba\xa3nh c\xc3\xb3 s\xe1\xba\xb5n \xc4\x91\xc3\xa3 \xc4\x91\xc6\xb0\xe1\xbb\xa3c embeedings = facenet\n+            print(\'Calculating features for images\')\n+            dataset = facenet.get_dataset("Dataset/FaceData/processed")\n+            paths, labels = facenet.get_image_paths_and_labels(dataset)\n+            nrof_images = len(paths)\n+            nrof_batches_per_epoch = int(math.ceil(1.0*nrof_images / 1000))\n+            emb_arrays = np.zeros((nrof_images, embedding_size))\n+            for i in range(nrof_batches_per_epoch):\n+                start_index = i*1000\n+                end_index = min((i+1)*1000, nrof_images)\n+                paths_batch = paths[start_index:end_index]\n+                images = facenet.load_data(paths_batch, False, False, 160)\n+                feed_dict = { images_placeholder:images, phase_train_placeholder:False }\n+                # tr\xe1\xba\xa3 v\xe1\xbb\x81 danh s\xc3\xa1ch embedded vectors\n+                emb_arrays[start_index:end_index,:] = sess.run(embeddings, feed_dict=feed_dict)\n+\n+            # emb_arrays s\xe1\xba\xbd l\xc6\xb0u vectors c\xe1\xbb\xa7a t\xe1\xba\xa5t c\xe1\xba\xa3 c\xc3\xa1c h\xc3\xacnh\n+\n             while (True):\n                 frame = cap.read()\n                 frame = imutils.resize(frame, width=600)\n@@ -93,8 +110,16 @@ def main():\n                                 scaled = facenet.prewhiten(scaled)\n                                 scaled_reshape = scaled.reshape(-1, INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE, 3)\n                                 feed_dict = {images_placeholder: scaled_reshape, phase_train_placeholder: False}\n+\n+                                # vector c\xe1\xbb\xa7a khu\xc3\xb4n m\xe1\xba\xb7t \xc4\x91ang nh\xe1\xba\xadn \xc4\x91\xc6\xb0\xe1\xbb\xa3c c\xe1\xbb\xab camera\n                                 emb_array = sess.run(embeddings, feed_dict=feed_dict)\n \n+                                sim = cosine_similarity(emb_arrays, emb_array)\n+                                sim = np.squeeze(sim, axis = 1)\n+                                argmax = np.argsort(sim)[::-1][:1]\n+                                label = [labels[idx] for idx in argmax][0]\n+\n+                                # ph\xc3\xa2n l\xe1\xbb\x9bp t\xe1\xbb\xab \xc4\x91o\xe1\xba\xa1n n\xc3\xa0y\n                                 predictions = model.predict_proba(emb_array)\n                                 best_class_indices = np.argmax(predictions, axis=1)\n                                 best_class_probabilities = predictions[\n@@ -102,8 +127,6 @@ def main():\n                                 best_name = class_names[best_class_indices[0]]\n                                 print("Name: {}, Probability: {}".format(best_name, best_class_probabilities))\n \n-\n-\n                                 if best_class_probabilities > 0.8:\n                                     cv2.rectangle(frame, (bb[i][0], bb[i][1]), (bb[i][2], bb[i][3]), (0, 255, 0), 2)\n                                     text_x = bb[i][0]\n@@ -119,8 +142,8 @@ def main():\n                                 else:\n                                     name = "Unknown"\n \n-                except:\n-                    pass\n+                except Exception as e:\n+                    print(e)\n \n                 cv2.imshow(\'Face Recognition\', frame)\n                 if cv2.waitKey(1) & 0xFF == ord(\'q\'):\n@@ -129,5 +152,11 @@ def main():\n             cap.release()\n             cv2.destroyAllWindows()\n \n+main()\n \n-main()\n\\ No newline at end of file\n+def _most_similarity(embed_vecs, vec, labels):\n+  sim = cosine_similarity(embed_vecs, vec)\n+  sim = np.squeeze(sim, axis = 1)\n+  argmax = np.argsort(sim)[::-1][:1]\n+  label = [labels[idx] for idx in argmax][0]\n+  return label\n\\ No newline at end of file\ndiff --git a/src/face_rec_flask.py b/src/face_rec_flask.py\ndeleted file mode 100644\nindex 16868f2..0000000\n--- a/src/face_rec_flask.py\n+++ /dev/null\n@@ -1,117 +0,0 @@\n-from __future__ import absolute_import\n-from __future__ import division\n-from __future__ import print_function\n-\n-from flask import Flask\n-from flask import render_template , request\n-from flask_cors import CORS, cross_origin\n-import tensorflow as tf\n-import argparse\n-import facenet\n-import os\n-import sys\n-import math\n-import pickle\n-import align.detect_face\n-import numpy as np\n-import cv2\n-import collections\n-from sklearn.svm import SVC\n-import base64\n-\n-MINSIZE = 20\n-THRESHOLD = [0.6, 0.7, 0.7]\n-FACTOR = 0.709\n-IMAGE_SIZE = 182\n-INPUT_IMAGE_SIZE = 160\n-CLASSIFIER_PATH = \'../Models/facemodel.pkl\'\n-FACENET_MODEL_PATH = \'../Models/20180402-114759.pb\'\n-\n-# Load The Custom Classifier\n-with open(CLASSIFIER_PATH, \'rb\') as file:\n-    model, class_names = pickle.load(file)\n-print("Custom Classifier, Successfully loaded")\n-\n-tf.Graph().as_default()\n-\n-gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.6)\n-sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options, log_device_placement=False))\n-\n-\n-# Load the model\n-print(\'Loading feature extraction model\')\n-facenet.load_model(FACENET_MODEL_PATH)\n-\n-# Get input and output tensors\n-images_placeholder = tf.get_default_graph().get_tensor_by_name("input:0")\n-embeddings = tf.get_default_graph().get_tensor_by_name("embeddings:0")\n-phase_train_placeholder = tf.get_default_graph().get_tensor_by_name("phase_train:0")\n-embedding_size = embeddings.get_shape()[1]\n-pnet, rnet, onet = align.detect_face.create_mtcnn(sess, "align")\n-\n-\n-\n-app = Flask(__name__)\n-CORS(app)\n-\n-\n-\n-@app.route(\'/\')\n-@cross_origin()\n-def index():\n-    return "OK!";\n-\n-@app.route(\'/recog\', methods=[\'POST\'])\n-@cross_origin()\n-def upload_img_file():\n-    if request.method == \'POST\':\n-        # base 64\n-        name="Unknown"\n-        f = request.form.get(\'image\')\n-        w = int(request.form.get(\'w\'))\n-        h = int(request.form.get(\'h\'))\n-\n-        decoded_string = base64.b64decode(f)\n-        frame = np.fromstring(decoded_string, dtype=np.uint8)\n-        #frame = frame.reshape(w,h,3)\n-        frame = cv2.imdecode(frame, cv2.IMREAD_ANYCOLOR)  # cv2.IMREAD_COLOR in OpenCV 3.1\n-\n-        bounding_boxes, _ = align.detect_face.detect_face(frame, MINSIZE, pnet, rnet, onet, THRESHOLD, FACTOR)\n-\n-        faces_found = bounding_boxes.shape[0]\n-\n-        if faces_found > 0:\n-            det = bounding_boxes[:, 0:4]\n-            bb = np.zeros((faces_found, 4), dtype=np.int32)\n-            for i in range(faces_found):\n-                bb[i][0] = det[i][0]\n-                bb[i][1] = det[i][1]\n-                bb[i][2] = det[i][2]\n-                bb[i][3] = det[i][3]\n-                cropped = frame\n-                #cropped = frame[bb[i][1]:bb[i][3], bb[i][0]:bb[i][2], :]\n-                scaled = cv2.resize(cropped, (INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE),\n-                                    interpolation=cv2.INTER_CUBIC)\n-                scaled = facenet.prewhiten(scaled)\n-                scaled_reshape = scaled.reshape(-1, INPUT_IMAGE_SIZE, INPUT_IMAGE_SIZE, 3)\n-                feed_dict = {images_placeholder: scaled_reshape, phase_train_placeholder: False}\n-                emb_array = sess.run(embeddings, feed_dict=feed_dict)\n-                predictions = model.predict_proba(emb_array)\n-                best_class_indices = np.argmax(predictions, axis=1)\n-                best_class_probabilities = predictions[\n-                    np.arange(len(best_class_indices)), best_class_indices]\n-                best_name = class_names[best_class_indices[0]]\n-                print("Name: {}, Probability: {}".format(best_name, best_class_probabilities))\n-\n-                if best_class_probabilities > 0.8:\n-                    name = class_names[best_class_indices[0]]\n-                else:\n-                    name = "Unknown"\n-\n-\n-        return name;\n-\n-\n-if __name__ == \'__main__\':\n-    app.run(debug=True, host=\'0.0.0.0\',port=\'8000\')\n-\ndiff --git a/src/facenet.py b/src/facenet.py\nindex bfe6802..837e265 100644\n--- a/src/facenet.py\n+++ b/src/facenet.py\n@@ -29,7 +29,7 @@ from __future__ import print_function\n \n import os\n from subprocess import Popen, PIPE\n-import tensorflow as tf\n+import tensorflow.compat.v1 as tf\n import numpy as np\n from scipy import misc\n from sklearn.model_selection import KFold\n@@ -40,6 +40,8 @@ import re\n from tensorflow.python.platform import gfile\n import math\n from six import iteritems\n+import imageio\n+\n \n def triplet_loss(anchor, positive, negative, alpha):\n     """Calculate the triplet loss according to the FaceNet paper\n@@ -244,7 +246,7 @@ def load_data(image_paths, do_random_crop, do_random_flip, image_size, do_prewhi\n     nrof_samples = len(image_paths)\n     images = np.zeros((nrof_samples, image_size, image_size, 3))\n     for i in range(nrof_samples):\n-        img = misc.imread(image_paths[i])\n+        img = imageio.imread(image_paths[i])\n         if img.ndim == 2:\n             img = to_rgb(img)\n         if do_prewhiten:\n@@ -404,7 +406,8 @@ def get_model_filenames(model_dir):\n                 max_step = step\n                 ckpt_file = step_str.groups()[0]\n     return meta_file, ckpt_file\n-  \n+\n+# H\xc3\xa0m t\xc3\xadnh distance gi\xe1\xbb\xafa 2 vectors\n def distance(embeddings1, embeddings2, distance_metric=0):\n     if distance_metric==0:\n         # Euclidian distance\n@@ -467,7 +470,6 @@ def calculate_accuracy(threshold, dist, actual_issame):\n     return tpr, fpr, acc\n \n \n-  \n def calculate_val(thresholds, embeddings1, embeddings2, actual_issame, far_target, nrof_folds=10, distance_metric=0, subtract_mean=False):\n     assert(embeddings1.shape[0] == embeddings2.shape[0])\n     assert(embeddings1.shape[1] == embeddings2.shape[1])\ndiff --git a/video/a b/video/a\ndeleted file mode 100644\nindex 8b13789..0000000\n--- a/video/a\n+++ /dev/null\n@@ -1 +0,0 @@\n-\ndiff --git a/video/camtest.mp4 b/video/camtest.mp4\ndeleted file mode 100644\nindex a503c89..0000000\nBinary files a/video/camtest.mp4 and /dev/null differ'